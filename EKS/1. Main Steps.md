# 1. Create Elastic Kubernetes cluster

### Install EKS

Please follow the prerequisites doc before this.

### Install using Fargate

```
eksctl create cluster --name demo-cluster --region us-east-1 --fargate \
	--profile rispython
```

### Delete the cluster

```
eksctl delete cluster --name demo-cluster --region us-east-1
```



---

# 2.  Connect kubectl to an EKS cluster by creating a kubeconfig file

The¬†`kubectl`¬†command-line tool uses configuration information in¬†`kubeconfig`¬†files to communicate with the API server of a cluster.


```
aws eks update-kubeconfig --region region-code --name my-cluster
```


---


Since we are using fargate, we need to folloe this step.
But if we are using ec2 instances then we can avoid this step.
# Create fargate profile

```
eksctl create fargateprofile \
    --cluster demo-cluster \
    --region us-east-1 \
    --name alb-sample-app \
    --namespace game-2048
```


---


# 3.  Deploy the deployment, service and Ingress


```
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.5.4/docs/examples/2048/2048_full.yaml
```

`https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.5.4/docs/examples/2048/2048_full.yaml`

This file has all the configuration related to 
- deployment
- service
- ingress

[[Full]]

### üò¨ The Catch:

> You deployed an **Ingress resource**, but **no ingress controller is running yet** to interpret and act on it.

That means:
- No **AWS ALB** (Application Load Balancer) will be created
- The **Ingress rules** won't route traffic to the Service
- So, the app is basically **unreachable** from outside the cluster


---

# 4. Ingress Controller 

The **Ingress Controller** (in this case, the **AWS Load Balancer Controller**) is what watches for Ingress resources like `ingress-2048`, and **provisions an ALB** based on it.

Once it's running, it will:
1. Watch the `ingress-2048` resource
2. Create an AWS ALB
3. Configure target groups , on what port it should access the pods and rules
4. Route external traffic to your pods via the Service

So now we have to deploy the ingress controller, in our case ALB ingress controller.


---
## Pre-requisite
---

# Configure IAM OIDC provider 

```
eksctl utils associate-iam-oidc-provider --cluster $cluster_name --approve
```


- The **AWS Load Balancer Controller** is deployed as a **Kubernetes pod**.
- This pod needs to **interact with AWS services** like:
    - Creating an **Application Load Balancer (ALB)**
    - Managing **Target Groups**
    - Handling **Listeners** and **Rules**

üîí But to access AWS services securely, it must use **IAM permissions**.

1. Pod uses a Kubernetes Service Account
2. Service Account is linked to an IAM Role
	- This is done via **IAM Role for Service Account (IRSA)**.

3. OIDC connects the dots
	- The **EKS cluster gives an OIDC issuer URL** ‚Äî it's like the cluster‚Äôs ID to say, ‚ÄúHey, I can issue trusted tokens.‚Äù
	- You need to **register this URL with IAM as an Identity Provider**.
	- This tells AWS: ‚ÄúI trust tokens coming from this EKS cluster.‚Äù
	- **Once connected, you can link IAM roles to Kubernetes service accounts** ‚Äî so pods can safely access AWS services.

Final Note:
`OIDC allows Kubernetes service accounts to assume IAM roles securely via identity provider.`

---
# 5.  Setup ALB controller

You are trying to install an ALB controller.
Any controller is just a pod.
For this pod, we are trying to grant this pod access to AWS services like ALB - 
because ALB ingress controller has to create an Application Load Balancer, which it has to talk to the AWS api.

1. 
Download IAM policy

```
curl -O https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.11.0/docs/install/iam_policy.json
```

2. 
Create IAM Policy
```
aws iam create-policy \
    --policy-name AWSLoadBalancerControllerIAMPolicy \
    --policy-document file://iam_policy.json
```

3. 
Create a Kubernetes service account and an IAM role, and links them via OIDC using `eksctl`.
```
eksctl create iamserviceaccount \
  --cluster=<your-cluster-name> \
  --namespace=kube-system \
  --name=aws-load-balancer-controller \
  --role-name AmazonEKSLoadBalancerControllerRole \
  --attach-policy-arn=arn:aws:iam::<your-aws-account-id>:policy/AWSLoadBalancerControllerIAMPolicy \
  --approve
```
#### üß† What it does:
- Creates a service account in `kube-system`
- Creates an IAM role with trust policy linked to the OIDC provider
- Attaches the IAM policy to the role
- Annotates the service account to assume the IAM role


The service account is used by the controller pod. 
The IAM role provides AWS permissions, and 
`eksctl` links Kubernetes Service Account ‚ü∑ the IAM Role via OIDC.


‚úÖ **IAM Role Trust Policy**

- `eksctl` adds a trust policy to the IAM role.
- This trust relationship includes:

```
"Condition": {
  "StringEquals": {
    "<OIDC_PROVIDER>:sub": "system:serviceaccount:kube-system:aws-load-balancer-controller"
  }
}
```


---

# 6. Install AWS Load Balancer Controller using Helm

Add helm repo
```
helm repo add eks https://aws.github.io/eks-charts
```

Update the repo
```
helm repo update eks
```

Install
```
helm install aws-load-balancer-controller eks/aws-load-balancer-controller \            
  -n kube-system \
  --set clusterName=<your-cluster-name> \
  --set serviceAccount.create=false \
  --set serviceAccount.name=aws-load-balancer-controller \
  --set region=<region> \
  --set vpcId=<your-vpc-id>
```

Verify that the deployments are running.

```
kubectl get deployment -n kube-system aws-load-balancer-controller
```